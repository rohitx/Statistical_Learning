We now revisit the bias-variance decomposition.

(a) Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (or irreducible) error curves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The x-axis should represent the amount of flexibility in the method, and the y-axis should represent the values for each curve. There should be five curves. Make sure to label each one.

(b) Explain why each of the five curves has the shape displayed in part (a).

The bias decreasing with increasing flexibility. This is so because an increasing flexible model does not think of a form of the model a priori. The variance increases with flexibility because the larger flexibility causes overfitting which in turn increases the variance. The test MSE is a function of both bias and variance. In the beginning it is high as the bias is large but decreases as the flexibility increases. However, larger flexibility causes overfitting. Hence, the test MSE increases. The training MSE decreases are the flexibility increases and it continues to do because the overfitting reduces the variance. The Bayes classifier has the lowest error rate corresponding to the irreducible error. Bayes (irreducible) error - defines the lower limit, the test error is bounded below by the irreducible error due to variance in the error (epsilon) in the output values (0 <= value). When the training error is lower than the irreducible error, overfitting has taken place.